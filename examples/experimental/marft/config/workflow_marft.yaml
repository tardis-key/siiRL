# Copyright 2025, Shanghai Innovation Institute. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

dag_id: "marft_ppo_training_pipeline"
description: "This is MARFT DAG workflow configured via YAML."

actor_1_config: &actor1_config
  rollout.log_prob_micro_batch_size_per_gpu: 16
  rollout.tensor_model_parallel_size: 4
  rollout.gpu_memory_utilization: 0.3
  rollout.n: 1


actor_2_config: &actor2_config
  rollout.log_prob_micro_batch_size_per_gpu: 16
  rollout.tensor_model_parallel_size: 4
  rollout.gpu_memory_utilization: 0.3
  rollout.n: 1
  
nodes:
  - node_id: "rollout_reasoner"
    node_type: "MODEL_INFERENCE"
    node_role: "ROLLOUT"
    config: *actor1_config
    agent_group: 0
    dependencies: []
    user_options:
      train_cycle: 15
      pre_chat_template: "<|im_start|>system: Two LLM agents (Reasoner -> Actor) collaborate step-by-step to solve math problems. You are the **Reasoner**: Analyze the original problem, historical actions, and reflection data (if provided) to determine the critical next step. Guide the Actor by providing concise reasoning for the optimal operation.<|im_end|>\n <|im_start|> problem: {prompt} <|im_end|>\n <|im_start|> reasoner:  "

  - node_id: "rollout_actor"
    node_type: "MODEL_INFERENCE"
    node_role: "ROLLOUT"
    config: *actor2_config
    agent_group: 1
    dependencies: 
     - "rollout_reasoner"
    user_options:
      train_cycle: 15
      pre_chat_template: "<|im_start|>system: Two LLM agents (Reasoner -> Actor) collaborate step-by-step. You are the **Actor**: Execute operations using original problem, action history, and Reasoner's guidance. Give the final answer after '####'.<|im_end|>\n {prompt} <|im_start|> actor: "

  - node_id: "function_reward"
    node_type: "COMPUTE"
    node_role: "REWARD"
    agent_group: 1
    dependencies:
      - "rollout_actor"

  - node_id: "actor_1_old_log_prob"
    node_type: "MODEL_TRAIN"
    node_role: "ACTOR"
    only_forward_compute: true
    agent_group: 0
    config: *actor1_config    
    dependencies:
      - "function_reward"

  - node_id: "actor_2_old_log_prob"
    node_type: "MODEL_TRAIN"
    node_role: "ACTOR"
    only_forward_compute: true
    agent_group: 1
    config: *actor2_config    
    dependencies:
      - "actor_1_old_log_prob"

  - node_id: "critic_value"
    node_type: "MODEL_TRAIN"
    node_role: "CRITIC"
    agent_group: 1
    only_forward_compute: true
    dependencies:
      - "actor_2_old_log_prob"

  - node_id: "calculate_2_advantages"
    node_type: "COMPUTE"
    node_role: "ADVANTAGE"
    agent_group: 1
    dependencies:
      - "critic_value"

  - node_id: "calculate_1_advantages"
    node_type: "COMPUTE"
    node_role: "ADVANTAGE"
    agent_group: 0
    dependencies:
      - "calculate_2_advantages"


  - node_id: "critic_2_train"
    node_type: "MODEL_TRAIN"
    node_role: "CRITIC"
    agent_group: 1
    dependencies:
      - "calculate_1_advantages"

  - node_id: "actor_1_train"
    node_type: "MODEL_TRAIN"
    node_role: "ACTOR"
    agent_group: 0
    config: *actor1_config
    dependencies:
      - "critic_2_train"

  - node_id: "actor_2_train"
    node_type: "MODEL_TRAIN"
    node_role: "ACTOR"
    agent_group: 1
    config: *actor2_config
    dependencies:
      - "actor_1_train"

